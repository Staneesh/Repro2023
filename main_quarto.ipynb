{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Reproducible Research Project: Air Passengers Occupancy Prediction'\n",
        "author: 'Adam Foster, Maciej Staniszewski, Illia Baranochnikov'\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "    toc-expand: 1\n",
        "    toc-title: Contents\n",
        "    toc-location: body\n",
        "    smooth-scroll: true\n",
        "    theme:\n",
        "      light: flatly\n",
        "      dark: darkly\n",
        "title-block-banner: true\n",
        "---"
      ],
      "id": "6f7884b5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing Libraries\n"
      ],
      "id": "39268204"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import datetime\n",
        "from scipy.stats import norm\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "id": "57b5b82a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading the Dataset\n",
        "\n",
        "Air passenger data is downloaded to the `/data` subdirectory of the root project folder. We will use `pandas` to create a data frame with this data. \n"
      ],
      "id": "88a9c797"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = pd.read_csv('data/AirPassengers.xls', index_col=0)\n",
        "data.columns = [ 'Count' ] # Renaming `#Passengers` -> `Count` for convenience\n",
        "data.head()"
      ],
      "id": "8c5c2e1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.tail()"
      ],
      "id": "cc001065",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the dataset looks relatively simple. It contains monthly data about the number of air passengers from 1949 to 1960. Let's see more detailed description of the data using `pandas.describe()`:\n"
      ],
      "id": "1bdaa286"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.describe()"
      ],
      "id": "4ca9710b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having taken a better look we can note down a couple observations:\n",
        " - There are 144 observations\n",
        " - The distribution is centered around 280\n",
        " - The distribution is skewed towards larger values jugding from **quartiles** and **min-max** range\n",
        "\n",
        "Let's import libraries required for performing the analysis and forecasting outlined in the paper.\n",
        "\n",
        "# Time Series Modelling - ARIMA\n",
        "\n",
        "We will fit a simple **A**uto**R**egressive **I**ntegrate **M**oving **A**verage, or **ARIMA**, model to our time series of air passengers.\n",
        "\n",
        "First, we should plot the time series and it's first difference, as is customary:\n"
      ],
      "id": "fdeb1f12"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# First difference is computed by diffing values with shifted values. We then fill NAs with 0s to\n",
        "# handle the first difference.\n",
        "data[ 'Diff' ] = (data[ 'Count' ] - data[ 'Count' ].shift(1)).fillna(0)\n",
        "data.head()"
      ],
      "id": "d9851069",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.plot(figsize=(19, 10), subplots=True)"
      ],
      "id": "d595e199",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visual Inspection\n",
        "\n",
        "At the first glance we see that the data does not contain missing values. It's a discrete series, because we sample our values monthly. It appears seasonal, which is in line with the meaning of the values in the data frame - they reflect the number of air passengers, so it's natural that we observe more passengers during, for example, summer.\n",
        "\n",
        "## Train-Test Split\n",
        "There is no clear mention of the approach used to split the data into training and test sets. Judging by the final forecast visualisation, 1958 appeared to be the cutoff point between training and test sets. After this point there was an additional ARIMA curve until the end of the series used to forecast air passenger volumes in comparison with the actual time series.\n",
        "\n",
        "We will therefore set 1949-1957 as the training set and 1958-1960 as the test set.\n"
      ],
      "id": "48722b0b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = data.reset_index()\n",
        "data['Date'] = data.apply(lambda x: datetime.datetime.strptime(x['Month'], '%Y-%m'), axis = 1).dt.date\n",
        "data = data.drop(['Month'], axis = 1)"
      ],
      "id": "6fb9328b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train = data.loc[data['Date'] < datetime.date(1958, 1, 1)]\n",
        "train.tail()"
      ],
      "id": "7ccf7311",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test = data.loc[data['Date'] >= datetime.date(1958, 1, 1)]\n",
        "test.head()"
      ],
      "id": "707efe29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stationarity\n",
        "\n",
        "We should check if the series is stationary. As per visual inspection we see that it should not be. We will use the <ins>**A**ugumented **D**ickey-**F**uller</ins> (**ADF**) test ([*Wikipedia* link](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test)), which is a part of the `statsmodels` library.\n"
      ],
      "id": "3cda7084"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Small helper function for performing the DF test on a time series. \n",
        "def ADF(series):\n",
        "    (adf_test, adf_p) = sm.tsa.stattools.adfuller(series)[:2]\n",
        "    print(f\"ADF Test Statistic = {adf_test}, p-value = {adf_p}\")\n",
        "\n",
        "ADF(train[ 'Count' ])"
      ],
      "id": "cfce4b7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the *p-value* is outside the critical region, we **fail to reject the null** hypothesis about the stationarity of the series. This is in line with our initial expectations. We will assume that the series is non-stationary.\n",
        "\n",
        "The authors of the paper arrive at a different test statistic.\n",
        "\n",
        "They actually obtain the following test statistic which assumes the use of the entire time series (train + test).\n"
      ],
      "id": "debdbb2a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Small helper function for performing the DF test on a time series. \n",
        "def ADF(series):\n",
        "    (adf_test, adf_p) = sm.tsa.stattools.adfuller(series)[:2]\n",
        "    print(f\"ADF Test Statistic = {adf_test}, p-value = {adf_p}\")\n",
        "\n",
        "ADF(data[ 'Count' ])"
      ],
      "id": "b9f12455",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For completeness, let's also check the stationarity of the series of first differences:\n"
      ],
      "id": "8972f991"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ADF(train[ 'Diff' ])"
      ],
      "id": "77cc9d2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The p-value is still high enough for the null hypothesis not to be rejected at 10% confidence level.\n"
      ],
      "id": "5b282704"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ADF(data[ 'Diff' ])"
      ],
      "id": "435b7381",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extending the test to the entire series again, we **reject the null** at the 95% confidence level, better than the 0.07 p-value reported by the authors. This indicates the first differences are stationary and the the underlying series is I(1).\n",
        "\n",
        "The authors of the paper describe that a *logarithmic transformation* is another useful option in removing the trend and fluctuations in the series. Calculating the first difference was sufficient though.\n",
        "\n",
        "The steps that were taken by the authors include differencing and removing seasonality. They **did not** mention how was the seasonality removed - we can only guess here and perform our own estimations. \n",
        "\n",
        "With the process being classified as I(1), the authors proceeded to determine the order of AR and MA models for the complete ARIMA model using partial autocorrelation functions (PACF) and autocorrelation functions (ACF), respectively.\n",
        "\n",
        "## PACF and ACF\n",
        "\n",
        "Running PACF and ACF on the first differences on both training and overall datasets is perfomed and depicted below. The shapes of both PACF and ACF curves follow those produced by the authors with a closer match for the training set. A similar set of lags are statistically significant, as those in the paper.\n"
      ],
      "id": "7b718ae3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def autocorr(data_input, func_type, ci):\n",
        "    if(func_type == 'PACF'):\n",
        "        func_data = sm.tsa.stattools.pacf(data_input)\n",
        "    elif(func_type == 'ACF'):\n",
        "        func_data = sm.tsa.stattools.acf(data_input)\n",
        "    \n",
        "    t = len(data_input)\n",
        "    norminv = norm.ppf(ci + (1 - ci) / 2)\n",
        "    bound_upper = norminv / t**0.5\n",
        "    bound_lower = - norminv / t**0.5\n",
        "    curve_bound_upper = [bound_upper for i in range(0,len(func_data))]\n",
        "    curve_bound_lower = [bound_lower for i in range(0,len(func_data))]\n",
        "    \n",
        "    plt.plot(func_data, label = func_type)\n",
        "    plt.plot(curve_bound_upper, 'k--', label = 'Upper Bound')\n",
        "    plt.plot(curve_bound_lower, 'k--', label = 'Lower Bound')\n",
        "    plt.title(func_type)\n",
        "    plt.show()"
      ],
      "id": "c812a81b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "autocorr(data[ 'Diff' ], 'PACF', 0.95)"
      ],
      "id": "ea51295f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "autocorr(train[ 'Diff' ], 'PACF', 0.95)"
      ],
      "id": "ca0e6388",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "autocorr(data[ 'Diff' ], 'ACF', 0.95)"
      ],
      "id": "29e4bf7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "autocorr(train[ 'Diff' ], 'ACF', 0.95)"
      ],
      "id": "7059a596",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is some tendency to move towards zero over time in both PACF and ACF, indicating AR and MA processes are likely to be able to explain the underlying air passenger volume series. There are several spikes and drops outside of the 95% confidence interval bounds: using training data, PACF visibly exceeds bounds at lags 8, 10 and 12 and ACF visibly exceeds bounds at lags 4, 8 and 12. Therefore, it can be expected that the components might follow p = 8/10/12 AR and q = 4/8/12 MA processes.\n",
        "\n",
        "The authors of the paper, however, choose lower values for p and q, ending up with an ARIMA(2,1,2) model. This is likely chosen in order to maintain explainability and is supported by:\n",
        "- Maximum Likelihood Estimation results which maximise the probability of obtaining the observed data\n",
        "- Favourable AIC and BIC information criteria\n",
        "\n",
        "## ARIMA Model\n",
        "With the ARIMA inputs determined, we can train the model and predict the time series between 1958-1960.\n"
      ],
      "id": "970ce1de"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def arima_run(data_input, order_selection, print_output, return_model):\n",
        "    arima_out = ARIMA(data_input, order=order_selection)\n",
        "    arima_out_res = arima_out.fit()\n",
        "    if print_output:\n",
        "        print(arima_out_res.summary())\n",
        "        \n",
        "    arima_out_pred = arima_out_res.forecast(36)\n",
        "    full = pd.concat([data_input, arima_out_pred])    \n",
        "    if print_output:\n",
        "        plt.plot(full)\n",
        "        plt.title('ARIMA ' + str(order_selection))\n",
        "        plt.show()\n",
        "    \n",
        "    if return_model:\n",
        "        return full, arima_out_res\n",
        "    else:\n",
        "        return full"
      ],
      "id": "240f15a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**CALCULATE AIC AND BIC INFORMATION CRITERIA HERE**\n"
      ],
      "id": "79157515"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "full212, full212_model = arima_run(train['Diff'], (2,1,2), True, True)"
      ],
      "id": "95ace713",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "full210, full210_model = arima_run(train['Diff'], (2,1,0), False, True)"
      ],
      "id": "aa2bd7c9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "full012, full012_model = arima_run(train['Diff'], (0,1,2), False, True)"
      ],
      "id": "e82b6f54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "full212_series = []\n",
        "val = data['Count'][0]\n",
        "\n",
        "for i in full212:\n",
        "    val += i\n",
        "    full212_series.append(val)"
      ],
      "id": "0cedbff2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(data['Count'], label = 'Observed')\n",
        "plt.plot(full212_series, label = 'Predicted')\n",
        "plt.title('Air Passenger Volume Assuming ARIMA(2,1,2)')\n",
        "plt.show()"
      ],
      "id": "6a31811c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each of the ARIMAs chosen by the authors produced a poor fit in this exercise. The least concerning out of the three models was ARIMA(2,1,2) but still could not reproduce the visualised prediction in the paper. Whilst it increased the series over time with the long-term trend accurately, its variability diffused too quickly and it ignored the seasonality.\n",
        "\n",
        "### Calculating training errors and comparison with RMS in paper\n",
        "\n",
        "Below we have calculated training errors similarly to ones calculated by the authors of the original paper. As we can see, we were unable to replicate the results using ARIMA model.\n"
      ],
      "id": "5272b273"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for model_i in [\n",
        "    (\"ARIMA (2,1,2)\", full212_model, 1.5023),\n",
        "    (\"ARIMA (2,1,0)\", full210_model, 1.4721),\n",
        "    (\"ARIMA (0,1,2)\", full012_model, 1.0292)\n",
        "]:\n",
        "    print(f\"{model_i[0]}: RMSE={round(mean_squared_error(train['Diff'], model_i[1].predict(), squared=False),4)} (RMSE in paper = {model_i[2]})\")\n"
      ],
      "id": "577084f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to improve the forecast, more lags should be considered - these were significant in the PACF and ACF after all. In addition, modifying the functional form to a SARIMA model would better adapt to the data due to the seasonality in air passenger volumes. We have expanded on the paper by developing an alternative model which aims to reproduce the forecast of the authors more accurately and produce significantly better fit to the data.\n",
        "\n",
        "## SARIMA\n",
        "\n",
        "Using SARIMA instead of ARIMA for forecasting the AirPassengers dataset is better because SARIMA takes into account the seasonal patterns present in the data. The AirPassengers dataset shows regular peaks and troughs at specific intervals. SARIMA incorporates these seasonal components, along with autoregressive and moving average components, to capture the complex dynamics of the dataset more accurately. This results in improved predictions, especially when dealing with data that has clear seasonality like air passenger traffic. In summary, SARIMA is a preferable choice over ARIMA for forecasting the AirPassengers dataset due to its ability to handle seasonal patterns.\n",
        "\n",
        "### Time series decomposition\n"
      ],
      "id": "62ac0dbe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = seasonal_decompose(data['Count'], period=12, model='additive')\n",
        "result.plot()\n",
        "plt.show()"
      ],
      "id": "40d168f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the plots above, we can observe that there are definitely seasonal component. Hence, it would be a good idea to test SARIMA model that probably would be able to replicate the paper's results.\n",
        "\n",
        "Let's assume that authors forgot to describe that they use SARIMA model. So, we will try the following SARIMA models: SARIMA (2,1,2)(0,1,0,12), SARIMA (0,1,2)(0,1,0,12), SARIMA (2,1,0)(0,1,0,12).\n"
      ],
      "id": "7bbea409"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def run_sarima_model(order,seasonal_order, forecast_horizon=36, print_summary=False, print_plot=False):\n",
        "    mod = sm.tsa.statespace.SARIMAX(data['Count'][:-forecast_horizon], trend='c', order=order, seasonal_order=seasonal_order)\n",
        "    sarima_model = mod.fit()\n",
        "    if print_summary:\n",
        "        print(sarima_model.summary())\n",
        "\n",
        "    sarima_pred = sarima_model.forecast(forecast_horizon)\n",
        "    \n",
        "    if print_plot:\n",
        "        plt.plot(data['Count'], label = 'Observed')\n",
        "        plt.plot(pd.concat([data['Count'][:-forecast_horizon],sarima_pred]), label = 'Predicted')\n",
        "        plt.title('Air Passenger Volume')\n",
        "        plt.show()\n",
        "    \n",
        "    return sarima_model, sarima_pred"
      ],
      "id": "400d714b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sarima212_010_12, sarima212_010_12_pred = run_sarima_model((2,1,2), (0,1,0,12), print_plot = True)"
      ],
      "id": "5639e69c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sarima210_110_12, sarima210_110_12_pred = run_sarima_model((2,1,0), (0,1,0,12), print_plot = True)"
      ],
      "id": "5900184c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sarima012_110_12, sarima012_110_12_pred = run_sarima_model((0,1,2), (0,1,0,12), print_plot = True)"
      ],
      "id": "3eadf068",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, we managed to get predictions that take into account seasonal component and it is getting us closer to replicating the original results.\n",
        "\n",
        "Let's calculate training errors again.\n"
      ],
      "id": "30f50615"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for model_i in [\n",
        "    (\"SARIMA (2,1,2) (0,1,0,12)\", sarima212_010_12, 1.5023),\n",
        "    (\"SARIMA (2,1,0) (0,1,0,12)\", sarima210_110_12, 1.4721),\n",
        "    (\"SARIMA (0,1,2) (0,1,0,12)\", sarima012_110_12, 1.0292)\n",
        "]:\n",
        "    print(f\"{model_i[0]}: RMSE={round(mean_squared_error(data['Count'][:-36], model_i[1].predict(), squared=False),4)} (RMSE in paper = {model_i[2]})\")\n"
      ],
      "id": "6f128abe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparing to ARIMA models, we got much lower RMSE metric for SARIMA models. Unfortunately, we are still too far from the results presented in the paper.\n"
      ],
      "id": "f4a5db75"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}